# Study Log
Task | Thesis | Keyword | ArXiv | Code | Accept | Study 
:---: | :---: | :---: | :---: | :---: | :---: | :---: 
Semantic Segmentation | Fully Convolutional Networks for Semantic Segmentation | FCN | [ArXiv](https://arxiv.org/abs/1411.4038) | [GitHub](https://github.com/shelhamer/fcn.berkeleyvision.org?tab=readme-ov-file) | CVPR 2015 | [20240130](2024/FCN공부_20240130.pdf)
Semantic Segmentation | Rethinking Atrous Convolution for Semantic Image Segmentation | DeepLabv3 | [ArXiv](https://arxiv.org/abs/1706.05587) | No Code | CVPR 2017 | [20240202](2024/DeepLabv3공부_20240202.pdf) 
Semantic Segmentation | Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis | ESANet | [ArXiv](https://arxiv.org/abs/2011.06961) | [GitHub](https://github.com/TUI-NICR/ESANet) | ICRA 2021 | [20240205](2024/ESANet공부_20240205.pdf)
Semi-Supervised Learning | FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning | FreeMatch | [ArXiv](https://arxiv.org/abs/2205.07246) | [GitHub](https://github.com/microsoft/Semi-supervised-learning) | ICLR 2023 | [20240215](2024/FreeMatch_공부_20240215.pdf) 
Category Discovery | Generalized Category Discovery in Semantic Segmentation | GCDSS | [ArXiv](https://arxiv.org/abs/2311.11525) | [GitHub](https://github.com/JethroPeng/GCDSS) | ArXiv 2023 | [20240319](2024/GCDSS_석사알티자료_20240319.pdf) 
Category Discovery | Active Generalized Category Discovery | AGCD | [ArXiv](https://arxiv.org/abs/2403.04272) | [GitHub](https://github.com/mashijie1028/ActiveGCD) | CVPR 2024 | (1) [20240409](2024/AGCD공부_20240409.pdf) <br> (2) [20240409](2024/AGCD_석사알티자료_20240409.pdf) 
Category Discovery | Generalized Category Discovery | GCD | [ArXiv](https://arxiv.org/abs/2201.02609) | [GitHub](https://github.com/sgvaze/generalized-category-discovery) | CVPR 2022 | (1) [20240507](2024/GCD공부_20240507.pdf) <br> (2) [20240507](2024/GCD_석사알티자료_20240507.pdf) 
Semantic Segmentation | Semantic Segmentation with Active Semi-Supervised Learning | S4AL | [ArXiv](https://arxiv.org/abs/2203.10730) | [GitHub](https://github.com/aneesh3108/S4AL) | WACV 2023 | (1) [20240604](2024/S4AL_공부_20240604.pdf) <br> (2) [20240604](2024/S4AL_석사알티자료_20240604.pdf)  
Category Discovery | Learning to Discover Novel Visual Categories via Deep Transfer Clustering | NCD, DTC | [Arxiv](https://arxiv.org/abs/1908.09884) | [GitHub](https://github.com/k-han/DTC) | ICCV 2019 | (1) [20240716](2024/DTC공부_20240716.pdf) <br> (2) [20240716](2024/DTC_석사알티자료_20240716.pdf) 
Category Discovery | Dynamic Conceptional Contrastive Learning for Generalized Category Discovery | DCCL | [ArXiv](https://arxiv.org/abs/2303.17393) | [GitHub](https://github.com/TPCD/DCCL) | CVPR 2023 | [20240801_1640](2024/DCCL공부_20240801_1640.pdf)
Data Augmentation | ClassMix: Segmentation-Based Data Augmentation for Semi-Supervised Learning | ClassMix | [ArXiv](https://arxiv.org/abs/2007.07936) | [GitHub](https://github.com/WilhelmT/ClassMix) | WACV 2021 | [20240804_2056](2024/ClassMix_공부_20240804_2056.pdf)
Face Clustering | Linkage Based Face Clustering via Graph Convolution Network | GCN-Clustering | [ArXiv](https://arxiv.org/abs/1903.11306) | [GitHub](https://github.com/Zhongdao/gcn_clustering/) | CVPR 2019 | [20240804_2108](2024/GCN-Clustering공부_20240804_2108.pdf)
Finetuning | Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm | ActiveFT | [ArXiv](https://arxiv.org/abs/2303.14382) | [GitHub](https://github.com/yichen928/ActiveFT) | CVPR 2023 | (1) [20240807_0117](2024/ActiveFT공부_20240807_0117.pdf) <br> (2) [20240807_0117](2024/ActiveFT공부2_20240807_0117.pdf) 
Object Detection | Box-Level Active Detection | BLAD, ComPAS | [ArXiv](https://arxiv.org/abs/2303.13089) | [GitHub](https://github.com/lyumengyao/blad) | CVPR 2023 Highlight | (1) [20240807_0132](2024/BLAD공부_20240807_0132.pdf) <br> (2) [20240807_0132](2024/BLAD공부2_20240807_0132.pdf) 
Superpixel Algorithm | SEEDS: Superpixels Extracted via Energy-Driven Sampling | SEEDS | [ArXiv](https://arxiv.org/abs/1309.3848) | No Code | ArXiv 2013 | [20240824_1554](2024/SEEDS공부_20240824_1554.pdf) 
Object Detection | End-to-End Object Detection with Transformers | DETR | [ArXiv](https://arxiv.org/abs/2005.12872) | [GitHub](https://github.com/facebookresearch/detr) | ECCV 2020 | [20240925](2024/DETR_석사알티자료_20240925.pdf) 
Tracking | DINO-Tracker: Taming DINO for Self-Supervised  Point Tracking in a Single Video | DINO-Tracker | [ArXiv](https://arxiv.org/abs/2403.14548) | [GitHub](https://github.com/AssafSinger94/dino-tracker) | ECCV 2024 | [20241022](2024/DINO-Tracker_석사알티자료_20241022.pdf) 
Label Quatlity Evaluation | Estimating label quality and errors in semantic segmentation data via any model | cleanlab | [ArXiv](https://arxiv.org/abs/2307.05080) | [GitHub](https://github.com/cleanlab/cleanlab) |ICML 2023 Workshop | [20241120](2024/cleanlab_석사알티자료_20241120.pdf) 
Partial-Label Learning | CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label Learning | CroSel | [ArXiv](https://arxiv.org/abs/2303.10365) | [GitHub](https://github.com/jokersio-tsy/CroSel?tab=readme-ov-file) | CVPR 2024 | [20241204_1415](2024/CroSel_석사알티자료_20241204_1415.pdf) 
Classification | Robust Classification via Regression for Learning with Noisy Labels | SGN | [OpenReview](https://openreview.net/forum?id=wfgZc3IMqo) | [GitHub](https://github.com/ErikEnglesson/SGN) | ICLR 2024 | [20250106_1723](2025/SGN_석사알티자료_20250106_1723.pdf) 
Deep Active Learning toolkit | A Comparative Survey of Deep Active Learning | DeepAL+ | [ArXiv](https://arxiv.org/pdf/2203.13450) | [GitHub](https://github.com/SineZHAN/deepALplus) | ArXiv 2022 | [20250203](2025/DeepAL+_석사알티자료_20250203.pdf)
Image Classification | Active Label Correction Using Robust Parameter Update and Entropy Propagation | ALC | [pdf](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136810001.pdf) | No Code | ECCV 2022 | [20250217](2025/ALC_석사알티자료_20250217.pdf)  
Open-Vocabulary Instance Segmentation | Mask-free OVIS: Open-Vocabulary Instance Segmentation  without Manual Mask Annotations | Mask-free OVIS | [ArXiv](https://arxiv.org/abs/2303.16891) | [GitHub](https://github.com/Vibashan/Mask-free-OVIS) | CVPR 2023 | [20250320_1442](2025/Mask-freeOVIS_팀알티자료_20250320_1442.pdf) 
Prompt Learning | Learning to Prompt for Vision-Language Models | CoOp | [ArXiv](https://arxiv.org/abs/2109.01134) | [GitHub](https://github.com/KaiyangZhou/CoOp) | IJCV 2022 | [20250331_1123](2025/CoOp_석사알티자료_20250331_1123.pdf) 
Visual Representation Learning | Multi-Modal Large Language Models are Effective Vision Learners | LMVR | [pdf](https://openaccess.thecvf.com/content/WACV2025/papers/Sun_Multi-Modal_Large_Language_Models_are_Effective_Vision_Learners_WACV_2025_paper.pdf) | [GitHub](https://github.com/lisun-ai/LMVR) | WACV 2025 | [20250413_1956](2025/LMVR_공부_20250413_1956.pdf)
LLM | LLaMA: Open and Efficient Foundation Language Models | LLaMA | [ArXiv](https://arxiv.org/abs/2302.13971) | [GitHub](https://github.com/meta-llama/llama) | ArXiv 2023 | [20250416_0112](2025/LLaMA_공부_20250416_0112.pdf)
VLM | Visual Instruction Tuning | LLaVA | [ArXiv](https://arxiv.org/abs/2304.08485) | [GitHub](https://github.com/haotian-liu/LLaVA) | NeurIPS 2023 Oral | [20250418_0017](2025/LLaVA공부_20250418_0017.pdf)
LLVM | MoAI: Mixture of All Intelligence  for Large Language and Vision Models | MoAI | [ArXiv](https://arxiv.org/abs/2403.07508) | [GitHub](https://github.com/ByungKwanLee/MoAI) | ECCV 2024 | [20250429_0048](2025/MoAI공부_20250429_0048.pdf)
LLVM | CoLLaVO: Crayon Large Language and Vision mOdel | CoLLaVO | [ArXiv](https://arxiv.org/abs/2402.11248) | [GitHub](https://github.com/ByungKwanLee/CoLLaVO?tab=readme-ov-file) | ACL 2024 | [20250430_0022](2025/Collavo공부_20250430_0022.pdf)
Efficient Finetuning | QLORA: Efficient Finetuning of Quantized LLMs | QLORA | [ArXiv](https://arxiv.org/abs/2305.14314) | [GitHub](https://github.com/artidoro/qlora) | NeurIPS 2023 oral | [2020506_0050](2025/QLORA공부_20250506_0050.pdf)
Post-Training Quantization | Q-VLM: Post-training Quantization for Large Vision-Language Models | Q-VLM | [ArXiv](https://arxiv.org/abs/2410.08119) | [GitHub](https://github.com/ChangyuanWang17/QVLM) | NeurIPS 2024 | [2020506_0058](2025/Q-VLM공부_20250506_0058.pdf)
Parameter-Efficient Continual learning | Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters | MoE-Adapters4CL | [ArXiv](https://arxiv.org/abs/2403.11549) | [GitHub](https://github.com/JiazuoYu/MoE-Adapters4CL) | CVPR 2024 | [20250516_0330](2025/MoE-Adapters4CL공부_20250516_0330.pdf)
Continual Learning | Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models | ZSCL | [ArXiv](https://arxiv.org/abs/2303.06628) | [GitHub](https://github.com/Thunderbeee/ZSCL) | ICCV 2023 | [20250518_2345](2025/ZSCL공부_20250518_2345.pdf)
LLVM | Phantom of Latent for Large Language and Vision Models | Phantom | [ArXiv](https://arxiv.org/abs/2409.14713) | [GitHub](https://github.com/ByungKwanLee/Phantom) | Under Review | [20250521_0112](2025/Phantom공부_20250521_0112.pdf)
Parameter-Efficient Continual Learning | SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning | SD-LoRA | [ArXiv](https://arxiv.org/abs/2501.13198) | [GitHub](https://github.com/WuYichen-97/SD-Lora-CL?tab=readme-ov-file) | ICLR 2025 Oral | [20250604_0122](2025/SD-LoRA공부_20250604_0122.pdf)
Multimodal Dialogue Response Generation | BI-MDRG: Bridging Image History in  Multimodal Dialogue Response Generation | BI-MDRG | [ArXiv](https://arxiv.org/abs/2408.05926) | [GitHub](https://github.com/hee-suk-yoon/BI-MDRG) | ECCV 2024 | [20250605_0203](2025/BI-MDRG공부_20250605_0203.pdf)
Language Priors Benchmark | VLind-Bench: Measuring Language Priors in Large Vision-Language Models | VLind-Bench | [ArXiv](https://arxiv.org/abs/2406.08702) | [GitHub](https://github.com/klee972/vlind-bench) | NAACL 2025 Findings | [20250613_0225](2025/VLind-Bench공부_20250613_0225.pdf)
Open-Vocabulary Semantic Segmentation | Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation | NACLIP | [ArXiv](https://arxiv.org/abs/2404.08181) | [GitHub](https://github.com/sinahmr/NACLIP/tree/main) | WACV 2025 | [20250616_1135](2025/NACLIP공부_20250616_1135.pdf)
Representation Bending | Representation Bending for Large Language Model Safety | RepBend | [ArXiv](https://arxiv.org/abs/2504.01550) | [GitHub](https://github.com/AIM-Intelligence/RepBend) | ACL 2025 | [20250619_1444](2025/RepBend공부_20250619_1444.pdf)
Image-Text Matching | MASS: Overcoming Language Bias in Image-Text Matching | MASS | [ArXiv](https://arxiv.org/abs/2501.11469) | No Code | AAAI 2025 | [20250621_1742](2025/MASS공부_20250621_1742.pdf)
Weakly Supervised Semantic Segmentation | Exploring CLIP’s Dense Knowledge for Weakly Supervised Semantic Segmentation | ExCEL | [ArXiv](https://arxiv.org/abs/2503.20826) | [GitHub](https://github.com/zwyang6/ExCEL) | CVPR 2025 | (1) [20250625_0024](2025/ExCEL공부_20250625_0024.pdf) <br> (2) [20250630_1308](2025/ExCEL_석사알티자료_20250630_1308.pdf)
Referring Image Segmentation | Extending CLIP’s Image-Text Alignment to Referring Image Segmentation | RISCLIP | [ArXiv](http://arxiv.org/abs/2306.08498) | No Code | NAACL 2024 | [20250711_0156](2025/RISCLIP공부_20250711_0156.pdf)
Open-Vocabulary Semantic Segmentation | SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference | SCLIP | [ArXiv](https://arxiv.org/abs/2312.01597) | [GitHub](https://github.com/wangf3014/SCLIP) | ECCV 2024 | [20250719_1707](2025/SCLIP공부_20250719_1707.pdf)
Weakly Supervised Semantic Segmentation | Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation | WeCLIP | [ArXiv](https://arxiv.org/abs/2406.11189) | [GitHub](https://github.com/zbf1991/WeCLIP) | CVPR 2024 Highlight | [20250719_1721](2025/WeCLIP공부_20250719_1721.pdf)
Weakly Supervised Semantic Segmentation | Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation | SeCO | [ArXiv](https://arxiv.org/abs/2402.18467) | [GitHub](https://github.com/zwyang6/SeCo) | CVPR 2024 | [20250719_1722](2025/SeCO공부_20250719_1722.pdf)
Weakly Supervised Semantic Segmentation | Token Contrast for Weakly-Supervised Semantic SegmentationToken Contrast for Weakly-Supervised Semantic Segmentation | ToCo | [ArXiv](https://arxiv.org/abs/2303.01267) | [GitHub](https://github.com/rulixiang/ToCo) | CVPR 2023 | [20250719_1722](2025/ToCo공부_20250719_1722.pdf)
Open-Vocabulary Semantic Segmentation | ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference | ClearCLIP | [ArXiv](https://arxiv.org/abs/2407.12442) | [GitHub](https://github.com/mc-lan/ClearCLIP) | ECCV 2024 | (1) [20250720_0106](2025/ClearCLIP공부_20250720_0106.pdf) <br> (2) [20250724_1431](2025/ClearCLIP_머신팀알티자료_20250724_1431.pdf)
Open-Vocabulary Semantic Segmentation | Extract Free Dense Labels from CLIP | MaskCLIP | [ArXiv](https://arxiv.org/abs/2112.01071) | [GitHub](https://github.com/chongzhou96/MaskCLIP?tab=readme-ov-file) | ECCV 2022 Oral | [20250720_1722](2025/MaskCLIP공부_20250720_1722.pdf)
Open-Vocabulary Semantic Segmentation | ProxyCLIP: Proxy Attention Improves CLIP  for Open-Vocabulary Segmentation | ProxyCLIP | [ArXiv](https://arxiv.org/abs/2408.04883) | [GitHub](https://github.com/mc-lan/ProxyCLIP?tab=readme-ov-file) | ECCV 2024 | [20250722_0105](2025/ProxyCLIP공부_20250722_0105.pdf)
Retrieval-Augmented Generation | VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents | VDocRAG | [ArXiv](https://arxiv.org/abs/2504.09795) | [GitHub](https://github.com/nttmdlab-nlp/VDocRAG) | CVPR 2025 | [20250811_2141](2025/VDocRAG공부_20250811_2141.pdf)
Open-Vocabulary Object Detection | Simple Open-Vocabulary Object Detection with Vision Transformers | OWL-VIT v1 | [ArXiv](https://arxiv.org/abs/2205.06230) | [GitHub](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit) | ECCV 2022 | [20250812_2243](2025/OWL-VIT공부_20250812_2243.pdf)
Open-Vocabulary Object Detection | Scaling Open-Vocabulary Object Detection | OWL-VIT v2 | [ArXiv](https://arxiv.org/abs/2306.09683) | [GitHub](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit) | NeurIPS 2023 | [20250812_2243](2025/OWL-VIT공부_20250812_2243.pdf)
Open-Vocabulary Semantic Segmentation | Effective SAM Combination for Open-Vocabulary Semantic Segmentation | ESC-Net | [ArXiv](https://arxiv.org/abs/2411.14723) | No Code | CVPR 2025 | [20250821_2117](2025/ESCNet_머신팀알티자료_20250821_2117.pdf)
2D-to-3D Inverse Rendering | LUDVIG: Learning-Free Uplifting of 2D  Visual Features to Gaussian Splatting Scenes | LUDVIG | [Arxiv](https://arxiv.org/abs/2410.14462) | [GitHub](https://github.com/naver/ludvig) | ICCV 2025 | [20250917_1553](2025/LUDVIG_머신팀알티자료_20250917_1553.pdf)
Semantic Segmentation | Revisiting Superpixels for Active Learning in Semantic Segmentation with  Realistic Annotation Costs | Spx | [OpenAccess](https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.html) | [GitHub](https://github.com/cailile/Revisiting-Superpixels-for-Active-Learning) | CVPR 2021 | (1) [20240824_1526](2024/Spx공부_20240824_1526.pdf) <br> (2) [20251005_0157](2025/A2LC_베이스라인정리_20251005_0157.pdf)
Semantic Segmentation | Adaptive Superpixel for Active Learning in Semantic Segmentation | MerSpx | [ArXiv](https://arxiv.org/abs/2303.16817) | [GitHub](https://github.com/ml-postech/adaptive-superpixel-for-active-learning-in-semantic-segmentation) | ICCV 2023 | (1) [20240827_0108](2024/MerSpx_공부_20240827_0108.pdf) <br> (2) [20250310_0008](2025/MerSpx_석사알티자료_20250310_0008.pdf) <br> (3) [20251005_0157](2025/A2LC_베이스라인정리_20251005_0157.pdf)
Semantic Segmentation | Active Learning for Semantic Segmentation with Multi-class Label Query | MulSpx | [ArXiv](https://arxiv.org/abs/2309.09319) | [GitHub](https://github.com/sehyun03/MulActSeg) | NeurIPS 2023 | (1) [20240827_1356](2024/MulSpx_공부_20240827_1356.pdf) <br> (2) [20251005_0157](2025/A2LC_베이스라인정리_20251005_0157.pdf)
Semantic Segmentation | Active Label Correction for Semantic Segmentation with Foundation Models | ALC | [ArXiv](https://arxiv.org/abs/2403.10820) | [GitHub](https://github.com/ml-postech/active-label-correction) | ICML 2024 | (1) [20240813_0144](2024/ALC_공부_20240813_0144.pdf) <br> (2) [20240821_0343](2024/ALC_석사알티자료_20240821_0343.pdf) <br> (3) [20251005_0157](2025/A2LC_베이스라인정리_20251005_0157.pdf)
Robotic Manipulation | UAD: Unsupervised Affordance Distillation  for Generalization in Robotic Manipulation | UAD | [ArXiv](https://arxiv.org/abs/2506.09284) | [GitHub](https://github.com/TangYihe/unsup-affordance) | ICRA 2025 (Best Paper Finalist) | [20251020_2216](2025/UAD공부_20251020_2216.pdf)
OCR | DeepSeek-OCR: Contexts Optical Compression | DeepSeek-OCR | [Paper](https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf) | [GitHub](https://github.com/deepseek-ai/DeepSeek-OCR?tab=readme-ov-file) | ArXiv 2025 | [20251022_1128](2025/DeepSeek-OCR공부_20251022_1128.pdf) 
ChatGPT-Atlas | ChatGPT-Atlas | ChatGPT-Atlas | ChatGPT-Atlas | ChatGPT-Atlas | ChatGPT-Atlas | [20251022_1128](2025/ChatGPT-Atlas_20251022_1128.pdf) 
